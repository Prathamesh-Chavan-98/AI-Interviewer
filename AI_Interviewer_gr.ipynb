{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prathamesh-Chavan-98/AI-Interviewer/blob/main/AI_Interviewer_gr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT4kbcOdxUht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6fb33b9a-55cb-4577-e0fb-b1d41c94f1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: community in /usr/local/lib/python3.10/dist-packages (1.0.0b1)\n",
            "Requirement already satisfied: chroma in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (from community) (3.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from Flask->community) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask->community) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from Flask->community) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask->community) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from Flask->community) (1.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask->community) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement getpass (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for getpass\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.25.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.5)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain community langchain chroma\n",
        "!pip install openai\n",
        "!pip install getpass\n",
        "!pip install groq\n",
        "!pip install pypdf\n",
        "!pip install pymupdf\n",
        "!pip install python-dotenv\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install langchain_community\n",
        "from getpass import getpass\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "import fitz\n",
        "from langchain.document_loaders import TextLoader\n",
        "import fitz\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain import hub\n",
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kuNRujsjtrOQ",
        "outputId": "b7940eef-71ac-46a1-cd12-9b463d507557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "groq_api_key = userdata.get(\"groq-api-key\")\n",
        "langchain_api_key = userdata.get(\"langchain-api-key\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2j31jqJ7z9nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# connecting with llm (llama-3.3-70b-versatile)"
      ],
      "metadata": {
        "id": "lJ3izPpK3Z2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "GROQ_API_KEY=groq_api_key\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Retrieve the API key\n",
        "api_key = groq_api_key\n",
        "\n",
        "# Check if the API key is available\n",
        "if not api_key:\n",
        "    raise ValueError(\"API key not found. Set GROQ_API_KEY in the .env file or environment variables.\")\n",
        "\n",
        "# Initialize the Groq client\n",
        "client = Groq(api_key=api_key)\n",
        "\n",
        "# Send a chat completion request\n",
        "try:\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"hii i am Prathamesh Chavan\",\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "\n",
        "    # Print the response\n",
        "    print(chat_completion.choices[0].message.content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ougeHWdg0EU3",
        "outputId": "a0a8febf-f075-4be2-931e-f3a00dbf10a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Prathamesh Chavan, it's nice to meet you. Is there something I can help you with or would you like to chat?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the PDF document and Chunking\n"
      ],
      "metadata": {
        "id": "tK3T5G0l3ks6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PDF document\n",
        "loader = PyPDFLoader(\"/content/PRC Resume.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "# Split the document into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "XL585EHK0EXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Embeddings"
      ],
      "metadata": {
        "id": "aCsbaf564AvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Create a vector store (Chroma) from the document chunks\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
        "\n",
        "# Create a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Load a pre-built RAG prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1hDY0Cij0Eax",
        "outputId": "ec7143c3-315b-4418-a9f4-c7c815f3a2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Docs Formatting"
      ],
      "metadata": {
        "id": "6B6UbeRcPof8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to format documents\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Function to generate a response using RAG\n",
        "def generate_rag_response(question):\n",
        "    # Retrieve relevant documents\n",
        "    relevant_docs = retriever.get_relevant_documents(question)\n",
        "\n",
        "    if not relevant_docs:\n",
        "        return \"No relevant documents found.\"\n",
        "\n",
        "    # Format the retrieved documents as context\n",
        "    context = format_docs(relevant_docs)\n",
        "\n",
        "    # Fill the prompt with retrieved context and the question\n",
        "    formatted_prompt = prompt.format(context=context, question=question)\n",
        "\n",
        "    # Get the response from the LLM\n",
        "    response = get_groq_response(formatted_prompt)\n",
        "\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "wRYhBDWw0Egs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using groq for all LLM related tasks"
      ],
      "metadata": {
        "id": "dH5-4YEiOO4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_groq_response(prompt, llm_name=\"llama-3.3-70b-versatile\"):\n",
        "    \"\"\"\n",
        "    Gets a response from the Groq API.\n",
        "\n",
        "    Args:\n",
        "        prompt: The prompt to send to the API.\n",
        "        llm_name: The name of the LLM to use.\n",
        "\n",
        "    Returns:\n",
        "        The response from the API.\n",
        "    \"\"\"\n",
        "    # Access the groq_api_key from the global scope\n",
        "    global groq_api_key\n",
        "\n",
        "    client = Groq(\n",
        "        api_key=groq_api_key,\n",
        "    )\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"you are a helpful assistant.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=llm_name,\n",
        "    )\n",
        "\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "G3twuWxN_aRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User skills & AOI input"
      ],
      "metadata": {
        "id": "cUNkD35HO7SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect user input about their skills and area of interest\n",
        "user_skills = input(\"Enter your skills (comma-separated): \").strip().split(',')\n",
        "user_area_of_interest = input(\"Enter your area of interest: \").strip()\n",
        "\n",
        "print(f\"\\nSkills: {user_skills}\")\n",
        "print(f\"Area of Interest: {user_area_of_interest}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg08YNTv0Eio",
        "outputId": "19229ba5-ece8-48e8-8af5-f644c0d910ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your skills (comma-separated): data science \n",
            "Enter your area of interest: data science\n",
            "\n",
            "Skills: ['data science']\n",
            "Area of Interest: data science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation of Questions"
      ],
      "metadata": {
        "id": "7kuoubMpPFl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all input data into a query prompt\n",
        "def generate_relevant_questions():\n",
        "    question_prompt = f\"\"\"\n",
        "    Generate 10 relevant and very perticular moderate level interview questions for a candidate based on the following information generate 4 questions based on resume and project and skills in resume 3 on area of interest and 3 on skills of candidate:\n",
        "    - Resume Content: {splits}\n",
        "    - Skills: {user_skills}\n",
        "    - Area of Interest: {user_area_of_interest}\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the response and extract content as string\n",
        "    response = generate_rag_response(question_prompt)\n",
        "    return response  # Access the content attribute of AIMessage\n",
        "\n",
        "# Generate and display questions\n",
        "questions = generate_relevant_questions()\n",
        "\n",
        "# Print the generated questions\n",
        "print(\"\\nTop 10 Relevant Questions:\")\n",
        "for idx, question in enumerate(questions.split('\\n'), 1):\n",
        "    print(f\"{idx}. {question}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQULDOaj0Eki",
        "outputId": "b2202e7b-54ef-480c-d658-ac2ba15610e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Relevant Questions:\n",
            "1. Here are 10 interview questions for the candidate: \n",
            "2. 4 based on resume and project: \n",
            "3. 1. How did you engineer the navigation system for Hydrominex, and what technologies did you use?\n",
            "4. 2. Can you explain your experience with machine learning software for real-time weather forecasting and alerts?\n",
            "5. 3. How did you optimize retrieval accuracy in your AI Interviewer project to handle complex queries?\n",
            "6. 4. What was your role in building the automated news summarization and analysis tool, and what technologies did you use?\n",
            "7. 3 based on area of interest (data science): \n",
            "8. 5. What do you think are the most significant challenges in the field of data science, and how do you propose to address them?\n",
            "9. 6. Can you describe a project where you applied data science techniques to solve a real-world problem?\n",
            "10. 7. How do you stay updated with the latest developments and advancements in the field of data science?\n",
            "11. 3 based on skills (data science): \n",
            "12. 8. How do you handle missing or inconsistent data in a dataset, and what techniques do you use for data preprocessing?\n",
            "13. 9. Can you explain the differences between supervised, unsupervised, and reinforcement learning, and provide examples of each?\n",
            "14. 10. How do you evaluate the performance of a machine learning model, and what metrics do you use to measure its effectiveness?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accepting Answers"
      ],
      "metadata": {
        "id": "58KaB3zoPKHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to dynamically generate questions using RAG\n",
        "def generate_relevant_questions():\n",
        "    question_prompt = f\"\"\"\n",
        "    Generate 10 relevant and very perticular moderate level interview questions for a candidate based on the following information generate 4 questions based on resume and project and skills in resume 3 on area of interest and 3 on skills of candidate:\n",
        "    - Resume Content: {splits}\n",
        "    - Skills: {user_skills}\n",
        "    - Area of Interest: {user_area_of_interest}\n",
        "    \"\"\"\n",
        "    # Call your RAG function to generate the questions\n",
        "    response = generate_rag_response(question_prompt)  # Assuming this function is defined and works\n",
        "    return response.split(\"\\n\")  # Split the response into individual questions\n",
        "\n",
        "# Fetch questions from the RAG function\n",
        "questions = generate_relevant_questions()\n",
        "\n",
        "# Interactive function to display questions and capture answers sequentially\n",
        "def interactive_questionnaire(questions):\n",
        "    answers = []  # Store the answers\n",
        "    print(\"Interactive Q&A Session:\\n\")\n",
        "    for idx, question in enumerate(questions, 1):\n",
        "        question = question.strip()  # Clean up any whitespace\n",
        "        if question:  # Ignore empty lines\n",
        "            print(f\"Question {idx}: {question}\")  # Display the question\n",
        "            answer = input(\"Your Answer: \")  # Get the user's answer\n",
        "            answers.append((question, answer))  # Store the question-answer pair\n",
        "            print()  # Add spacing for better readability\n",
        "    return answers\n",
        "\n",
        "# Call the interactive Q&A process\n",
        "answers = interactive_questionnaire(questions)\n",
        "\n",
        "# Display all questions and answers at the end\n",
        "print(\"\\nYour Responses:\\n\")\n",
        "for idx, (question, answer) in enumerate(answers, 1):\n",
        "    print(f\"{idx}. {question}\")\n",
        "    print(f\"   Your Answer: {answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "fBfwWQ8X0Esk",
        "outputId": "453a190f-daf5-4a55-c5c0-b42823482049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive Q&A Session:\n",
            "\n",
            "Question 1: Here are 10 interview questions for the candidate:\n",
            "Your Answer: ok\n",
            "\n",
            "Question 2: 4 based on resume and project:\n",
            "Your Answer: ok\n",
            "\n",
            "Question 3: 1. How did you engineer a robust navigation system for safe vehicle operation in adverse weather using machine learning?\n",
            "Your Answer: l\n",
            "\n",
            "Question 4: 2. Can you explain the technical details of your Hydrominex project, including the machine learning algorithms used?\n",
            "Your Answer: l\n",
            "\n",
            "Question 5: 3. How did you optimize retrieval accuracy in your AI Interviewer project to handle complex queries?\n",
            "Your Answer: l\n",
            "\n",
            "Question 6: 4. What was your role in the development of the automated news summarization and analysis tool?\n",
            "Your Answer: l\n",
            "\n",
            "Question 8: 3 based on area of interest (data science):\n",
            "Your Answer: ok\n",
            "\n",
            "Question 9: 5. What do you think are the most significant challenges in data science, and how do you stay updated with the latest developments?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-7142ec85f4f0>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Call the interactive Q&A process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractive_questionnaire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Display all questions and answers at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-7142ec85f4f0>\u001b[0m in \u001b[0;36minteractive_questionnaire\u001b[0;34m(questions)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Ignore empty lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Question {idx}: {question}\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Display the question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your Answer: \"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the user's answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Store the question-answer pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add spacing for better readability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving QA pairs in Langchain Memory"
      ],
      "metadata": {
        "id": "Du4uXVlZPOS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Initialize memory\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Add Q&A pairs to memory\n",
        "for question, answer in answers:\n",
        "    memory.save_context({\"question\": question}, {\"answer\": answer})\n",
        "\n",
        "# Access stored conversations\n",
        "stored_conversations = memory.load_memory_variables({})\n",
        "print(\"Stored Q&A:\", stored_conversations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nITJalaS0EvQ",
        "outputId": "f8b15ab7-29dd-4c37-e49c-17595ada3dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored Q&A: {'history': \"Human: Based on the provided context, here are 10 interview questions for the candidate:\\nAI: l\\nHuman: 4 questions based on resume and project:\\nAI: l\\nHuman: 1. How did you utilize machine learning in your Hydrominex project for safe vehicle operation in adverse weather?\\nAI: k\\nHuman: 2. Can you explain the technical stack used in your AI Interviewer project?\\nAI: l\\nHuman: 3. How did you optimize data preprocessing in your Automated News Summarization and Analysis tool?\\nAI: l\\nHuman: 4. What was your role in the development of the navigation system in the Hydrominex project?\\nAI: \\nHuman: 3 questions based on area of interest (data science):\\nAI: \\nHuman: 5. What inspired you to pursue data science, and how do you stay updated with the latest trends?\\nAI: \\nHuman: 6. Can you explain a challenging data science problem you've encountered and how you overcame it?\\nAI: l\\nHuman: 7. How do you think data science can be applied to real-world problems, and what contributions do you hope to make?\\nAI: l\\nHuman: 3 questions based on skills (data science):\\nAI: l\\nHuman: 8. How do you handle missing values in a dataset, and what techniques do you use for data imputation?\\nAI: l\\nHuman: 9. Can you explain the concept of overfitting in machine learning and how to prevent it?\\nAI: l\\nHuman: 10. How do you evaluate the performance of a machine learning model, and what metrics do you use?\\nAI: l\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-d684d8af7a72>:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Judging the answers"
      ],
      "metadata": {
        "id": "MPox6yOfTdX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l# Function to dynamically generate questions using RAG (already exists in your previous code)\n",
        "def generate_relevant_questions():\n",
        "    question_prompt = f\"\"\"\n",
        "    Generate 10 relevant and very particular moderate level interview questions for a candidate based on the following information.\n",
        "    Generate 4 questions based on the resume and project, 3 based on the area of interest, and 3 based on the skills of the candidate:\n",
        "    - Resume Content: {splits}\n",
        "    - Skills: {user_skills}\n",
        "    - Area of Interest: {user_area_of_interest}\n",
        "    \"\"\"\n",
        "    # Call your RAG function to generate the questions\n",
        "    response = generate_rag_response(question_prompt)  # Assuming this function is defined and works\n",
        "    return response.split(\"\\n\")  # Split the response into individual questions\n",
        "\n",
        "# Function to evaluate answers using Groq LLM\n",
        "def judge_answers_groq(qa_pairs):\n",
        "    scored_responses = []  # List to store scored evaluations\n",
        "\n",
        "    for idx, (question, answer) in enumerate(qa_pairs, 1):\n",
        "        # Create the judging prompt\n",
        "        judging_prompt = f\"\"\"\n",
        "        Evaluate the candidate's response to the following question based on relevance, clarity, and correctness.\n",
        "        Strictly judge the answer for core concepts, depth of understanding, and conciseness.\n",
        "        Provide a score out of 10 (whole number only) .\n",
        "\n",
        "        Question: {question}\n",
        "        Answer: {answer}\n",
        "\n",
        "        Your evaluation should be in this format:\n",
        "        - Score: <score out of 10>\n",
        "        - Justification: <reasoning>\n",
        "        \"\"\"\n",
        "\n",
        "        # Call Groq LLM for evaluation\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": judging_prompt}\n",
        "            ],\n",
        "            model=\"llama-3.3-70b-versatile\"\n",
        "        )\n",
        "\n",
        "        # Extract the response content\n",
        "        evaluation = chat_completion.choices[0].message.content.strip()\n",
        "        scored_responses.append((question, answer, evaluation))\n",
        "\n",
        "    return scored_responses\n",
        "\n",
        "# Generate the list of questions from the candidate's information\n",
        "questions = generate_relevant_questions()\n",
        "\n",
        "# Interactive function to display questions and capture answers sequentially\n",
        "def interactive_questionnaire(questions):\n",
        "    answers = []  # Store the answers\n",
        "    print(\"Interactive Q&A Session:\\n\")\n",
        "    for idx, question in enumerate(questions, 1):\n",
        "        question = question.strip()  # Clean up any whitespace\n",
        "        if question:  # Ignore empty lines\n",
        "            print(f\"Question {idx}: {question}\")  # Display the question\n",
        "            answer = input(\"Your Answer: \")  # Get the user's answer\n",
        "            answers.append((question, answer))  # Store the question-answer pair\n",
        "            print()  # Add spacing for better readability\n",
        "    return answers\n",
        "\n",
        "# Call the interactive Q&A process to get candidate's answers\n",
        "answers = interactive_questionnaire(questions)\n",
        "\n",
        "# Now, evaluate the answers using Groq LLM\n",
        "judged_results = judge_answers_groq(answers)\n",
        "\n",
        "# Display the results (scoring and justifications)\n",
        "print(\"\\nEvaluation Results:\\n\")\n",
        "for idx, (question, answer, evaluation) in enumerate(judged_results, 1):\n",
        "    print(f\"Q{idx}: {question}\")\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print(f\"Evaluation:\\n{evaluation}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI_mKFIRSrcg",
        "outputId": "97b66a27-110d-4455-8b28-8798990d0902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive Q&A Session:\n",
            "\n",
            "Question 1: Here are 10 moderate-level interview questions for the candidate:\n",
            "Your Answer: ok\n",
            "\n",
            "Question 2: 4 based on the resume and project:\n",
            "Your Answer: ok\n",
            "\n",
            "Question 3: 1. How did you leverage machine learning for real-time weather forecasting in your Hydrominex project?\n",
            "Your Answer: ok\n",
            "\n",
            "Question 4: 2. Can you explain the role of sensor fusion with GPS and radar in enhancing obstacle detection?\n",
            "Your Answer: l\n",
            "\n",
            "Question 5: 3. How did you optimize retrieval accuracy to handle complex queries in your AI Interviewer project?\n",
            "Your Answer: l\n",
            "\n",
            "Question 6: 4. What techniques did you use for text preprocessing in your Automated News Summarization and Analysis tool?\n",
            "Your Answer: l\n",
            "\n",
            "Question 8: 3 based on the area of interest (data science):\n",
            "Your Answer: l\n",
            "\n",
            "Question 9: 5. How do you stay updated with the latest advancements in data science?\n",
            "Your Answer: l\n",
            "\n",
            "Question 10: 6. What do you think are the most significant challenges in data science, and how do you address them?\n",
            "Your Answer: l\n",
            "\n",
            "Question 11: 7. Can you explain a recent data science project you worked on and your role in it?\n",
            "Your Answer: l\n",
            "Your Answer: l\n",
            "\n",
            "Question 13: 3 based on the skills (data science):\n",
            "\n",
            "Question 14: 8. How do you handle missing data in a dataset, and what techniques do you use for data imputation?\n",
            "Your Answer: \n",
            "\n",
            "Question 15: 9. Can you explain the difference between supervised and unsupervised learning in data science?\n",
            "Your Answer: l\n",
            "\n",
            "Question 16: 10. How do you evaluate the performance of a machine learning model, and what metrics do you use?\n",
            "Your Answer: l\n",
            "\n",
            "\n",
            "Evaluation Results:\n",
            "\n",
            "Q1: Here are 10 moderate-level interview questions for the candidate:\n",
            "Answer: ok\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response of \"ok\" does not address the question, lacks relevance, clarity, and correctness, and does not demonstrate any understanding of the core concepts or the ability to provide concise and meaningful answers to the interview questions presented.\n",
            "\n",
            "Q2: 4 based on the resume and project:\n",
            "Answer: ok\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The response \"ok\" is extremely brief and lacks any meaningful content, relevance, clarity, or correctness in relation to the question. It does not demonstrate any understanding of the core concepts or provide any depth of knowledge regarding the resume and project.\n",
            "\n",
            "Q3: 1. How did you leverage machine learning for real-time weather forecasting in your Hydrominex project?\n",
            "Answer: ok\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response of \"ok\" does not provide any relevant, clear, or correct information regarding how they leveraged machine learning for real-time weather forecasting in their Hydrominex project, demonstrating a complete lack of understanding or explanation of the core concepts involved.\n",
            "\n",
            "Q4: 2. Can you explain the role of sensor fusion with GPS and radar in enhancing obstacle detection?\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer provided is incomplete and does not address the question about the role of sensor fusion with GPS and radar in enhancing obstacle detection. It lacks relevance, clarity, and correctness, failing to demonstrate any understanding of the core concepts related to sensor fusion and its application in obstacle detection.\n",
            "\n",
            "Q5: 3. How did you optimize retrieval accuracy to handle complex queries in your AI Interviewer project?\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response is completely irrelevant and lacks any information or explanation regarding the optimization of retrieval accuracy for handling complex queries in their AI Interviewer project. The answer provided is just a single letter \"l\" without any context or meaning, indicating a complete failure to address the question.\n",
            "\n",
            "Q6: 4. What techniques did you use for text preprocessing in your Automated News Summarization and Analysis tool?\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response is empty and does not provide any information about the techniques used for text preprocessing in their Automated News Summarization and Analysis tool, failing to demonstrate relevance, clarity, or correctness.\n",
            "\n",
            "Q7: 3 based on the area of interest (data science):\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The response \"l\" is completely irrelevant and lacks any semblance of clarity or correctness in relation to the field of data science. It does not demonstrate any understanding of core concepts or provide any concise and meaningful information.\n",
            "\n",
            "Q8: 5. How do you stay updated with the latest advancements in data science?\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response is completely irrelevant and lacks any meaningful content, as it only contains a single letter \"l\" without providing any information on how they stay updated with the latest advancements in data science.\n",
            "\n",
            "Q9: 6. What do you think are the most significant challenges in data science, and how do you address them?\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer provided is completely irrelevant and lacks any substance or information related to the question about the challenges in data science and how to address them. It appears to be a single letter \"l\" without any context or explanation, indicating a severe lack of understanding or effort in responding to the question.\n",
            "\n",
            "Q10: 7. Can you explain a recent data science project you worked on and your role in it?\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The candidate's response is completely irrelevant and lacks any meaningful information. The answer \"l\" does not provide any insight into a recent data science project or the candidate's role in it, failing to demonstrate any understanding or experience in the field of data science.\n",
            "\n",
            "Q11: 3 based on the skills (data science):\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer \"l\" is not relevant to the question, lacks clarity, and does not demonstrate any understanding of data science concepts. It appears to be a random character rather than a thoughtful response, resulting in a complete lack of correctness and depth of understanding.\n",
            "\n",
            "Q12: 8. How do you handle missing data in a dataset, and what techniques do you use for data imputation?\n",
            "Answer: \n",
            "Evaluation:\n",
            "To evaluate the candidate's response, I would need the actual answer provided by the candidate. However, since the answer isn't provided, I will create a hypothetical answer and then evaluate it based on the criteria given.\n",
            "\n",
            "Hypothetical Answer:\n",
            "\"When dealing with missing data, the first step is to understand the nature of the missing data, whether it's missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR). This understanding helps in choosing the appropriate technique for data imputation. Techniques I use include mean/median/mode imputation for numerical/categorical data, respectively, regression imputation where the missing value is predicted using a regression model based on other features, and more advanced methods like K-Nearest Neighbors (KNN) imputation or multiple imputation by chained equations (MICE). It's also important to evaluate the impact of imputation on the analysis by comparing results with and without imputation or using sensitivity analysis.\"\n",
            "\n",
            "- Score: 8\n",
            "- Justification: The answer covers core concepts like understanding the nature of missing data and lists several appropriate techniques for data imputation, showing a good depth of understanding. However, it lacks a bit in conciseness and could delve deeper into the advantages and disadvantages of each imputation method, or discuss when to use each, to achieve a perfect score.\n",
            "\n",
            "Q13: 9. Can you explain the difference between supervised and unsupervised learning in data science?\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer is completely irrelevant and lacks any content, therefore it does not demonstrate any understanding of the core concepts of supervised and unsupervised learning in data science. A valid response would require a clear explanation of the differences between these two types of learning, including their definitions, applications, and examples, which is entirely missing in this case.\n",
            "\n",
            "Q14: 10. How do you evaluate the performance of a machine learning model, and what metrics do you use?\n",
            "Answer: l\n",
            "Evaluation:\n",
            "- Score: 0\n",
            "- Justification: The answer provided is incomplete and lacks any relevant information regarding the evaluation of a machine learning model's performance or the metrics used. A proper answer should discuss various metrics such as accuracy, precision, recall, F1 score, mean squared error, R-squared, etc., and explain how these metrics are used to assess the model's performance. The given response does not demonstrate any understanding of the core concepts related to machine learning model evaluation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8P6XVwopSrsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eDsIhTLjSrvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUguFmRGSrx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NhsDuxpPSr0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s39pnzc3Sr3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZuyG4zBSr7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}